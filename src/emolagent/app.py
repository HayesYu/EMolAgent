"""
EMolAgent Streamlit ä¸»åº”ç”¨

æä¾›åŸºäº Web çš„ç”¨æˆ·ç•Œé¢ï¼Œé›†æˆ LangChain Agent è¿›è¡Œåˆ†å­è®¡ç®—å’ŒçŸ¥è¯†é—®ç­”ã€‚
"""

import os
import json
import time
import datetime
import re
import shutil
from dataclasses import dataclass
from typing import Any

import streamlit as st
import extra_streamlit_components as stx

from emolagent.utils.logger import logger
from emolagent.utils.paths import get_resource_path, get_project_root

from emolagent.database import db
from emolagent.core.tools import (
    search_molecule_in_db,
    build_and_optimize_cluster,
    build_multiple_clusters,
    run_dm_infer_pipeline,
    compress_directory,
    get_task_queue_status,
)

from emolagent.knowledge import (
    search_knowledge,
    build_index,
    get_index_stats,
    LITERATURE_PATH,
)

from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langchain.agents.structured_output import ToolStrategy
from langgraph.checkpoint.memory import InMemorySaver
from langchain_google_genai import ChatGoogleGenerativeAI

from emolagent.visualization import (
    create_structure_preview_html, 
    load_structure_from_db,
    load_all_structures_from_db,
    get_structure_count_from_db,
    create_gaussian_view_style_viewer,
    create_orbital_viewer,
    find_orbital_files,
    find_li_deformation_files,
    create_li_deformation_viewer,
    create_analysis_visualization_html,
    find_esp_files,
    create_esp_viewer,
)
import streamlit.components.v1 as components


DEFAULT_MODEL_PATH = get_resource_path("models", "nnenv.ep154.pth")

ADMIN_USERS = ["hayes"]

WELCOME_MESSAGE = """æ‚¨å¥½ï¼æˆ‘æ˜¯ EMolAgentï¼Œæ‚¨çš„è®¡ç®—åŒ–å­¦ AI åŠ©æ‰‹ã€‚

æˆ‘å…·å¤‡ä¸¤å¤§æ ¸å¿ƒèƒ½åŠ›ï¼š

ğŸ”¬ **åˆ†å­å›¢ç°‡è®¡ç®—**
ä»æœ¬åœ°æ•°æ®åº“æ£€ç´¢åˆ†å­ã€æ„å»ºå¹¶ä¼˜åŒ–å›¢ç°‡ç»“æ„ï¼Œé¢„æµ‹ HOMO/LUMOã€å¶æçŸ©åŠé™ç”µåŠ¿ç­‰ç”µå­æ€§è´¨ã€‚
ç¤ºä¾‹ï¼šã€Œè¯·æ„å»ºä¸€ä¸ªåŒ…å« 1ä¸ªLiç¦»å­ã€3ä¸ªDMEåˆ†å­ å’Œ 1ä¸ªFSIé˜´ç¦»å­ çš„å›¢ç°‡ã€

ğŸ“š **æ–‡çŒ®çŸ¥è¯†é—®ç­”**
åŸºäºæ•°ç™¾ç¯‡ AI for Science å’Œç”µè§£æ¶²é¢†åŸŸæ–‡çŒ®ï¼Œå›ç­”ç›¸å…³å­¦æœ¯é—®é¢˜ã€‚
ç¤ºä¾‹ï¼šã€Œä»€ä¹ˆæ˜¯æº¶å‰‚åŒ–ç»“æ„ï¼ŸCIPå’ŒSSIPæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿã€ã€Œä»‹ç»ä¸€ä¸‹ GNN åœ¨åˆ†å­æ€§è´¨é¢„æµ‹ä¸­çš„åº”ç”¨ã€

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘å°†ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼"""

CUSTOM_SYSTEM_PREFIX = """
ä½ æ˜¯ä¸€ä¸ªè®¡ç®—åŒ–å­¦ AI åŠ©æ‰‹ EMolAgentã€‚ä½ æœ‰ä¸¤å¤§æ ¸å¿ƒèƒ½åŠ›ï¼š

## èƒ½åŠ›ä¸€ï¼šåˆ†å­å›¢ç°‡è®¡ç®—
è¯·éµå¾ªä»¥ä¸‹å·¥ä½œæµæ¥å¤„ç†ç”¨æˆ·çš„åˆ†å­è®¡ç®—è¯·æ±‚ï¼š

### é‡è¦ï¼šè¯†åˆ«ç”¨æˆ·æ„å›¾
ç”¨æˆ·æ„å›¾å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼Œè¯·ä»”ç»†åˆ¤æ–­ï¼š

1. **åªç”Ÿæˆç»“æ„ï¼ˆä¸åˆ†æï¼‰**ï¼š
   - å…³é”®è¯ï¼šã€Œç”Ÿæˆç»“æ„ã€ã€Œæ„å»ºå›¢ç°‡ã€ã€Œåˆ›å»ºåˆ†å­ã€
   - **ä¸åŒ…å«**ï¼šã€Œåˆ†æã€ã€Œç”µå­ç»“æ„ã€ã€Œé¢„æµ‹æ€§è´¨ã€ã€ŒHOMOã€ã€ŒLUMOã€ç­‰
   - æ“ä½œï¼šåªè°ƒç”¨æ„å»ºå·¥å…·ï¼Œ**ä¸è¦è°ƒç”¨** `Run_Inference_Pipeline`

2. **ç”Ÿæˆå¹¶åˆ†æï¼ˆå®Œæ•´æµç¨‹ï¼‰**ï¼š
   - å…³é”®è¯ï¼šã€Œç”Ÿæˆå¹¶åˆ†æã€ã€Œè®¡ç®—ç”µå­ç»“æ„ã€ã€Œé¢„æµ‹æ€§è´¨ã€ã€Œè¿›è¡Œåˆ†æã€ã€Œç”µå­ç»“æ„åˆ†æã€
   - æ“ä½œï¼šè°ƒç”¨æ„å»ºå·¥å…· + `Run_Inference_Pipeline`

3. **å¯¹å·²æœ‰ç»“æ„è¿›è¡Œåˆ†æ**ï¼š
   - å…³é”®è¯ï¼šã€Œå¯¹ä¸Šé¢çš„ç»“æ„è¿›è¡Œåˆ†æã€ã€Œåˆ†æåˆšæ‰çš„ç»“æ„ã€ã€Œç»§ç»­åˆ†æã€
   - æ“ä½œï¼šä»å¯¹è¯å†å²æ‰¾åˆ° `optimized_db` è·¯å¾„ï¼Œåªè°ƒç”¨ `Run_Inference_Pipeline`

### âš ï¸ å…³é”®ï¼šå•é…æ–¹ vs å¤šé…æ–¹
- **å•é…æ–¹**ï¼šç”¨æˆ·åªæè¿°äº†ä¸€ç§é…æ–¹ï¼ˆå¦‚"1Li+3DME+1FSI"ï¼‰
  - åªç”Ÿæˆç»“æ„ï¼š`Build_Structure_Only`
  - ç”Ÿæˆå¹¶åˆ†æï¼š`Build_and_Optimize` + `Run_Inference_Pipeline`

- **å¤šé…æ–¹**ï¼šç”¨æˆ·æè¿°äº†å¤šç§ä¸åŒé…æ–¹ï¼ˆå¦‚"æ„å»ºAé…æ–¹...ç„¶åæ„å»ºBé…æ–¹..."ï¼‰
  - **å¿…é¡»**ä½¿ç”¨ `Build_Multiple_Clusters` ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰é…æ–¹
  - åªç”Ÿæˆç»“æ„ï¼š`Build_Multiple_Clusters`ï¼ˆä¸è°ƒç”¨ Run_Inference_Pipelineï¼‰
  - ç”Ÿæˆå¹¶åˆ†æï¼š`Build_Multiple_Clusters` + `Run_Inference_Pipeline`

**ç¤ºä¾‹åˆ¤æ–­**ï¼š
- ã€Œæ„å»º 1Li+3DME+1FSI å’Œ 1Li+2DME+2FSI ä¸¤ä¸ªå›¢ç°‡ã€â†’ å¤šé…æ–¹ + åªç”Ÿæˆç»“æ„ â†’ `Build_Multiple_Clusters`ï¼ˆå®Œæ¯•ï¼‰
- ã€Œæ„å»º 1Li+3DME+1FSI å’Œ 1Li+2DME+2FSI ä¸¤ä¸ªå›¢ç°‡å¹¶è¿›è¡Œç”µå­ç»“æ„åˆ†æã€â†’ å¤šé…æ–¹ + åˆ†æ â†’ `Build_Multiple_Clusters` + `Run_Inference_Pipeline`
- ã€Œæ„å»º 1Li+3DME+1FSIã€â†’ å•é…æ–¹ + åªç”Ÿæˆç»“æ„ â†’ `Build_Structure_Only`ï¼ˆå®Œæ¯•ï¼‰

### å·¥ä½œæµæ­¥éª¤ï¼š

1.  **è§£æéœ€æ±‚**ï¼š
    * è¯†åˆ«ä¸­å¿ƒç¦»å­ã€æº¶å‰‚ã€é˜´ç¦»å­åŠå…¶æ•°é‡
    * åˆ¤æ–­æ˜¯å•é…æ–¹è¿˜æ˜¯å¤šé…æ–¹
    * **å…³é”®åˆ¤æ–­**ï¼šç”¨æˆ·æ˜¯å¦è¦æ±‚è¿›è¡Œç”µå­ç»“æ„åˆ†æ

2.  **æ•°æ®åº“æ£€ç´¢ (Search_Molecule_DB)**ï¼š
    * å¯¹æ¯ä¸ªåˆ†å­ï¼ˆæº¶å‰‚æˆ–é˜´ç¦»å­ï¼‰ï¼Œå…ˆè°ƒç”¨ `Search_Molecule_DB` æŸ¥åº“
    * Solvent æŸ¥ 'solvent' ç±»å‹ï¼ŒAnion æŸ¥ 'anion' ç±»å‹
    * å¦‚æœæ‰¾åˆ° `db_path`ï¼Œå‘Šè¯‰ç”¨æˆ·"å·²åœ¨åº“ä¸­æ‰¾åˆ° XXX"
    * å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ SMILES

3.  **å»ºæ¨¡ä¸ä¼˜åŒ–**ï¼š
    * å•é…æ–¹åªç”Ÿæˆç»“æ„ï¼š`Build_Structure_Only`
    * å•é…æ–¹å®Œæ•´åˆ†æï¼š`Build_and_Optimize` â†’ `Run_Inference_Pipeline`
    * å¤šé…æ–¹åªç”Ÿæˆç»“æ„ï¼š`Build_Multiple_Clusters`ï¼ˆ**åˆ°æ­¤ç»“æŸï¼Œä¸è¦è°ƒç”¨åˆ†æ**ï¼‰
    * å¤šé…æ–¹å®Œæ•´åˆ†æï¼š`Build_Multiple_Clusters` â†’ `Run_Inference_Pipeline`
    * æ„é€  JSON å‚æ•°æ—¶ï¼š
      - æœ‰ DB è·¯å¾„ï¼š`{"name": "DME", "path": "...", "count": 3}`
      - æ—  DB è·¯å¾„ï¼š`{"smiles": "...", "count": 3}`

4.  **ç”µå­ç»“æ„æ¨æ–­ (Run_Inference_Pipeline)**ï¼š
    * **ä»…å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚åˆ†ææ—¶æ‰è°ƒç”¨**
    * ä½¿ç”¨ä¸Šä¸€æ­¥è¿”å›çš„ `optimized_db` è·¯å¾„
    * å¯¹äºå¤šé…æ–¹ï¼Œåªéœ€è°ƒç”¨ä¸€æ¬¡ï¼Œä¼šå¤„ç†æ‰€æœ‰ç»“æ„

5.  **æœ€ç»ˆæŠ¥å‘Š**ï¼š
    * åªç”Ÿæˆç»“æ„ï¼šå±•ç¤º 3D é¢„è§ˆï¼Œæç¤ºç”¨æˆ·å¯åç»­åˆ†æ
    * æ‰§è¡Œäº†åˆ†æï¼šå±•ç¤ºç”µå­æ€§è´¨ï¼Œä¿ç•™ `[[DOWNLOAD:...]]` é“¾æ¥

### è®°ä½ï¼š
- ç”¨æˆ·æ²¡è¯´ã€Œåˆ†æã€ã€Œç”µå­ç»“æ„ã€â†’ ä¸è¦è°ƒç”¨ `Run_Inference_Pipeline`
- ç”¨æˆ·åç»­è¯´ã€Œåˆ†æä¸Šé¢çš„ç»“æ„ã€â†’ ä»å†å²æ‰¾ `optimized_db`ï¼Œè°ƒç”¨ `Run_Inference_Pipeline`
- å¤šé…æ–¹ = ä½¿ç”¨ `Build_Multiple_Clusters`ï¼Œä¸è¦å¤šæ¬¡è°ƒç”¨å•é…æ–¹å·¥å…·

## èƒ½åŠ›äºŒï¼šæ–‡çŒ®çŸ¥è¯†é—®ç­” (Search_Knowledge_Base)
å½“ç”¨æˆ·è¯¢é—®ä»¥ä¸‹ç±»å‹çš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨ `Search_Knowledge_Base` å·¥å…·ï¼š
- AI for Science ç›¸å…³æ¨¡å‹å’Œæ–¹æ³•ï¼ˆå¦‚ GNNã€Transformerã€æ‰©æ•£æ¨¡å‹ç­‰ï¼‰
- ç”µè§£æ¶²æ€§è´¨ã€æº¶å‰‚åŒ–ç»“æ„ã€ç¦»å­ä¼ è¾“æœºç†
- ç”µæ± ææ–™ã€é”‚ç¦»å­/é’ ç¦»å­ç”µæ± 
- åˆ†å­æ¨¡æ‹Ÿæ–¹æ³•ã€DFTè®¡ç®—ã€æœºå™¨å­¦ä¹ åŠ¿å‡½æ•°
- ä»»ä½•éœ€è¦æ–‡çŒ®æ”¯æ’‘çš„ç§‘å­¦æ¦‚å¿µè§£é‡Š

**çŸ¥è¯†é—®ç­”å·¥ä½œæµ**ï¼š
1. ç†è§£ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒæ¦‚å¿µ
2. è°ƒç”¨ `Search_Knowledge_Base` æœç´¢ç›¸å…³æ–‡çŒ®
3. åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ï¼Œç»“åˆä½ çš„çŸ¥è¯†è¿›è¡Œç»¼åˆå›ç­”
4. **å¿…é¡»å¼•ç”¨æ¥æº**ï¼Œæ ¼å¼å¦‚ï¼šã€Œæ ¹æ®æ–‡çŒ® [xxx.pdf] ...ã€

ã€æ³¨æ„ã€‘
* å¦‚æœç”¨æˆ·è¯´"3ä¸ªDME"ï¼Œæ„æ€æ˜¯ count=3ã€‚
* FSI é€šå¸¸æ˜¯é˜´ç¦»å­ã€‚
* ä¸€æ­¥æ­¥æ‰§è¡Œï¼Œä¸è¦è·³è¿‡"æŸ¥åº“"æ­¥éª¤ï¼Œå› ä¸ºåº“å†…æ„å‹è´¨é‡æœ€é«˜ã€‚
* å¯¹äºçŸ¥è¯†æ€§é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“æœç´¢ï¼Œç¡®ä¿å›ç­”æœ‰æ–‡çŒ®ä¾æ®ã€‚
"""

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="EMolAgent", page_icon="ğŸ§ª", layout="wide")


# ==============================================================================
# 1. è¾…åŠ©å‡½æ•°å®šä¹‰
# ==============================================================================

@st.cache_resource(ttl=86400)
def schedule_cleanup():
    """å®šæ—¶æ¸…ç†ä»»åŠ¡ã€‚"""
    db.cleanup_old_data(days=30)
    return True


def get_manager():
    return stx.CookieManager(key="auth_cookie_manager")


def validate_path_exists(path: str, description: str):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ç»ˆæ­¢ã€‚"""
    if not path or not os.path.exists(path):
        st.error(f"â›”ï¸ **é”™è¯¯ï¼šç»ˆæ­¢æ‰§è¡Œ**\n\næ‰¾ä¸åˆ°{description}ï¼š`{path}`\n\nè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        st.stop()
    return True


def get_user_workspace():
    """æ ¹æ® session_state ä¸­çš„ç”¨æˆ·ä¿¡æ¯å’Œå½“å‰ä¼šè¯IDç”Ÿæˆè·¯å¾„ã€‚"""
    if "user" in st.session_state and st.session_state["user"]:
        username = st.session_state["user"]["username"]
        safe_username = "".join([c for c in username if c.isalnum() or c in ("-", "_")])
        chat_id = st.session_state.get("current_chat_id", "temp")
        workspace = os.path.join(get_project_root(), "users", safe_username, "output", str(chat_id))
    else:
        workspace = os.path.join(get_project_root(), "users", "guest", "output", "temp")

    if not os.path.exists(workspace):
        os.makedirs(workspace, exist_ok=True)
    return workspace


def get_user_workspace_from_ids(username: str | None, chat_id: str | None):
    safe_username = "".join([c for c in (username or "guest") if c.isalnum() or c in ("-", "_")])
    safe_chat_id = str(chat_id or "temp")
    workspace = os.path.join(get_project_root(), "users", safe_username, "output", safe_chat_id)
    os.makedirs(workspace, exist_ok=True)
    return workspace


# ==============================================================================
# 2. Tools
# ==============================================================================

@dataclass
class Context:
    """è‡ªå®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ã€‚"""
    user_id: str | None = None
    username: str | None = None
    chat_id: str | None = None


@tool(
    "Search_Molecule_DB",
    description=(
        "Search for a molecule (solvent or anion) in the local calibrated database. "
        "Args: query_name (e.g., 'DME'), mol_type ('solvent' or 'anion'). "
        "Returns a string that includes db_path if found."
    ),
)
def tool_search_db(query_name: str, mol_type: str, runtime: ToolRuntime[Context]) -> str:
    """åœ¨æœ¬åœ°æ•°æ®åº“ä¸­æœç´¢åˆ†å­ã€‚"""
    user_ws = get_user_workspace_from_ids(runtime.context.username, runtime.context.chat_id)
    search_dir = os.path.join(user_ws, "search_cache")
    return search_molecule_in_db(query_name, mol_type, search_dir)


@tool(
    "Build_and_Optimize",
    description=(
        "Build a cluster and optimize it using UMA. "
        "Args: ion_name (str), solvents_json (JSON list), anions_json (JSON list). "
        "Each list item should have 'count' and either 'path' or 'smiles'."
    ),
)
def tool_build_optimize(ion_name: str, solvents_json: str, anions_json: str, runtime: ToolRuntime[Context]) -> str:
    """æ„å»ºå¹¶ä¼˜åŒ–å›¢ç°‡ã€‚"""
    try:
        solvents = json.loads(solvents_json) if solvents_json else []
        anions = json.loads(anions_json) if anions_json else []
    except Exception:
        return "Error parsing JSON inputs."

    user_ws = get_user_workspace_from_ids(runtime.context.username, runtime.context.chat_id)
    task_id = f"{time.strftime('%Y%m%d_%H%M%S')}_{time.time_ns()}"
    task_dir = os.path.join(user_ws, f"task_{task_id}")
    return build_and_optimize_cluster(ion_name, solvents, anions, task_dir)


@tool(
    "Build_Structure_Only",
    description=(
        "Build and optimize a molecular cluster structure WITHOUT running electronic structure analysis. "
        "Use this when user just wants to generate/build a SINGLE structure. "
        "Args: ion_name (str), solvents_json (JSON list), anions_json (JSON list). "
        "Returns the optimized structure path and a 3D visualization for user confirmation."
    ),
)
def tool_build_structure_only(ion_name: str, solvents_json: str, anions_json: str, runtime: ToolRuntime[Context]) -> str:
    """ä»…æ„å»ºç»“æ„ï¼Œä¸è¿›è¡Œç”µå­ç»“æ„åˆ†æã€‚"""
    try:
        solvents = json.loads(solvents_json) if solvents_json else []
        anions = json.loads(anions_json) if anions_json else []
    except Exception:
        return "Error parsing JSON inputs."

    user_ws = get_user_workspace_from_ids(runtime.context.username, runtime.context.chat_id)
    task_id = f"{time.strftime('%Y%m%d_%H%M%S')}_{time.time_ns()}"
    task_dir = os.path.join(user_ws, f"task_{task_id}")
    
    result = build_and_optimize_cluster(ion_name, solvents, anions, task_dir)
    
    try:
        res_dict = json.loads(result)
        if res_dict.get("success"):
            optimized_db = res_dict.get("optimized_db")
            return json.dumps({
                "success": True,
                "optimized_db": optimized_db,
                "task_dir": task_dir,
                "msg": f"ç»“æ„å·²ç”Ÿæˆå¹¶ä¼˜åŒ–å®Œæˆã€‚è·¯å¾„: {optimized_db}",
                "visualization_marker": f"[[STRUCTURE_PREVIEW:{optimized_db}]]"
            })
        return result
    except:
        return result


@tool(
    "Build_Multiple_Clusters",
    description=(
        "Build MULTIPLE clusters with DIFFERENT recipes in ONE call. "
        "USE THIS when user requests multiple different cluster configurations in a single request. "
        "For example: 'build 1Li+3DME+1FSI AND 1Li+2DME+2FSI' should use this tool ONCE, not Build_and_Optimize twice. "
        "Args: ion_name (str), recipes_json (JSON list of recipes). "
        "Each recipe: {'solvents': [{'name': 'DME', 'path': '...', 'count': 3}], 'anions': [{'name': 'FSI', 'path': '...', 'count': 1}]}. "
        "Returns the optimized DB path containing ALL clusters."
    ),
)
def tool_build_multiple_clusters(ion_name: str, recipes_json: str, runtime: ToolRuntime[Context]) -> str:
    """æ‰¹é‡æ„å»ºå¤šä¸ªä¸åŒé…æ–¹çš„å›¢ç°‡ã€‚"""
    try:
        recipes = json.loads(recipes_json) if recipes_json else []
    except Exception:
        return json.dumps({"success": False, "msg": "Error parsing recipes_json."})

    if not recipes or len(recipes) == 0:
        return json.dumps({"success": False, "msg": "No recipes provided."})

    user_ws = get_user_workspace_from_ids(runtime.context.username, runtime.context.chat_id)
    task_id = f"{time.strftime('%Y%m%d_%H%M%S')}_{time.time_ns()}"
    task_dir = os.path.join(user_ws, f"task_{task_id}")
    
    result = build_multiple_clusters(ion_name, recipes, task_dir)
    
    try:
        res_dict = json.loads(result)
        if res_dict.get("success"):
            optimized_db = res_dict.get("optimized_db")
            recipes_count = res_dict.get("recipes_count", len(recipes))
            return json.dumps({
                "success": True,
                "optimized_db": optimized_db,
                "task_dir": task_dir,
                "recipes_count": recipes_count,
                "msg": f"æˆåŠŸæ„å»º {recipes_count} ä¸ªé…æ–¹çš„å›¢ç°‡ã€‚è·¯å¾„: {optimized_db}",
                "visualization_marker": f"[[STRUCTURE_PREVIEW:{optimized_db}]]"
            })
        return result
    except:
        return result


@tool(
    "Run_Inference_Pipeline",
    description=(
        "Run DPTB inference and electronic structure analysis on optimized DB. "
        "Args: optimized_db_path (str), model_path (optional). "
        "Returns a string containing [[DOWNLOAD:...]] zip link on success."
    ),
)
def tool_infer_pipeline(optimized_db_path: str, model_path: str | None, runtime: ToolRuntime[Context]) -> str:
    """è¿è¡Œç”µå­ç»“æ„æ¨æ–­ã€‚"""
    if model_path in ["None", "", None]:
        model_path = DEFAULT_MODEL_PATH

    validate_path_exists(optimized_db_path, "Optimized DB")

    db_dir = os.path.dirname(optimized_db_path)
    parent_dir = os.path.dirname(db_dir)

    if os.path.basename(db_dir) == "final_optimized":
        task_root = parent_dir
    elif os.path.basename(db_dir).startswith("task_"):
        task_root = db_dir
    else:
        task_root = db_dir

    run_id = str(time.time_ns())
    infer_out = os.path.join(task_root, f"inference_results_{run_id}")
    
    # è·å–ç”¨æˆ· ID ç”¨äºæ—¥å¿—è¿½è¸ª
    user_id = None
    if runtime and runtime.context:
        user_id = runtime.context.username or runtime.context.user_id
    
    result_json_str = run_dm_infer_pipeline(
        optimized_db_path, 
        model_path, 
        infer_out,
        user_id=user_id
    )

    try:
        res_dict = json.loads(result_json_str)
        if res_dict.get("success"):
            csv_path = res_dict.get("csv_path")
            output_dir = res_dict.get("output_dir", infer_out)
            gpu_id = res_dict.get("gpu_id", "N/A")
            zip_base_name = os.path.join(task_root, f"analysis_package_{run_id}")
            zip_path = compress_directory(output_dir, zip_base_name)

            return (
                f"æ¨ç†å®Œæˆ (GPU {gpu_id})ã€‚\n"
                f"CSVæ‘˜è¦è·¯å¾„: {csv_path}\n"
                f"æ•°æ®é¢„è§ˆ: {res_dict.get('data_preview')}\n"
                f"[[ANALYSIS_VISUALIZATION:{optimized_db_path}|{infer_out}]]\n"
                f"[[DOWNLOAD:{zip_path}]]"
            )
        return f"æ¨ç†å‡ºé”™: {result_json_str}"
    except Exception as e:
        return f"Error processing inference results: {e}"


@tool(
    "Search_Knowledge_Base",
    description=(
        "Search the literature knowledge base for AI4Science and electrolyte-related content. "
        "Use this tool when user asks about: AI models, machine learning methods, electrolyte properties, "
        "battery materials, molecular simulation theories, or any scientific concepts. "
        "Args: query (str) - the search query in natural language, top_k (int, optional) - number of results. "
        "Returns relevant excerpts from academic papers with source citations."
    ),
)
def tool_search_knowledge(query: str, top_k: int = 5) -> str:
    """æœç´¢çŸ¥è¯†åº“ã€‚"""
    api_key = os.getenv("GOOGLE_API_KEY", "")
    if not api_key:
        return "Error: Google API Key not configured."
    
    try:
        results = search_knowledge(query, api_key, top_k=top_k)
        
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®å†…å®¹ã€‚è¯·å°è¯•æ¢ä¸€ç§è¡¨è¾¾æ–¹å¼æˆ–æ›´å…·ä½“çš„å…³é”®è¯ã€‚"
        
        output_parts = [f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³æ–‡çŒ®å†…å®¹ï¼š\n"]
        
        for i, r in enumerate(results, 1):
            output_parts.append(
                f"**[{i}] {r['source']}** (ç›¸å…³åº¦: {r['relevance_score']:.2f})\n"
                f"åˆ†ç±»: {r['category'] or 'æ ¹ç›®å½•'}\n"
                f"å†…å®¹æ‘˜è¦:\n> {r['content'][:500]}{'...' if len(r['content']) > 500 else ''}\n"
            )
        
        return "\n---\n".join(output_parts)
    
    except Exception as e:
        return f"çŸ¥è¯†åº“æœç´¢å‡ºé”™: {str(e)}"


TOOLS = [tool_search_db, tool_build_structure_only, tool_build_multiple_clusters, tool_build_optimize, tool_infer_pipeline, tool_search_knowledge]


# ==============================================================================
# 3. Agent åˆå§‹åŒ–
# ==============================================================================

@dataclass
class ResponseFormat:
    """ç»“æ„åŒ–å“åº”æ¨¡å¼ã€‚"""
    output: str


@st.cache_resource(show_spinner=False)
def get_checkpointer() -> InMemorySaver:
    return InMemorySaver()


def build_agent(model_name: str, temperature: float, api_key: str):
    """æ„å»ºå¹¶è¿”å› LangChain agentã€‚"""
    model = ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=api_key,
        temperature=temperature,
        timeout=30,
        max_output_tokens=2000,
    )

    checkpointer = get_checkpointer()

    agent = create_agent(
        model=model,
        tools=TOOLS,
        system_prompt=CUSTOM_SYSTEM_PREFIX,
        context_schema=Context,
        checkpointer=checkpointer,
    )
    return agent


# ==============================================================================
# 4. UIï¼šç™»å½• / ä¸»ç•Œé¢
# ==============================================================================

def login_ui(cookie_manager):
    """å¤„ç†ç™»å½•å’Œæ³¨å†Œçš„ UI æ¸²æŸ“ã€‚"""
    st.title("ğŸ§ª EMolAgent - è¯·å…ˆç™»å½•")
    tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])

    with tab1:
        with st.form("login_form"):
            username = st.text_input("ç”¨æˆ·å")
            password = st.text_input("å¯†ç ", type="password")
            submitted = st.form_submit_button("ç™»å½•")
            if submitted:
                user = db.login_user(username, password)
                if user:
                    st.session_state["user"] = user
                    st.session_state["current_chat_id"] = None
                    st.session_state["logout_flag"] = False
                    token = db.create_jwt_token(user["id"], user["username"])
                    expires = datetime.datetime.now() + datetime.timedelta(days=3)
                    cookie_manager.set("auth_token", token, expires_at=expires)
                    st.success("ç™»å½•æˆåŠŸï¼")
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

    with tab2:
        with st.form("register_form"):
            new_user = st.text_input("æ–°ç”¨æˆ·å")
            new_pass = st.text_input("æ–°å¯†ç ", type="password")
            confirm_pass = st.text_input("ç¡®è®¤å¯†ç ", type="password")
            submitted = st.form_submit_button("æ³¨å†Œ")
            if submitted:
                if new_user and new_pass and confirm_pass:
                    if new_pass != confirm_pass:
                        st.error("ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´")
                    elif db.register_user(new_user, new_pass):
                        st.success("æ³¨å†ŒæˆåŠŸï¼è¯·åˆ‡æ¢åˆ°ç™»å½•æ ‡ç­¾é¡µè¿›è¡Œç™»å½•ã€‚")
                    else:
                        st.error("ç”¨æˆ·åå·²å­˜åœ¨")
                else:
                    st.error("è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")


def normalize_chat_content(content: Any) -> str:
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, bytes):
        try:
            return content.decode("utf-8", errors="replace")
        except Exception:
            return str(content)

    if isinstance(content, list):
        parts: list[str] = []
        for item in content:
            if item is None:
                continue
            if isinstance(item, str):
                parts.append(item)
            elif isinstance(item, dict):
                text = item.get("text")
                if isinstance(text, str):
                    parts.append(text)
                else:
                    parts.append(json.dumps(item, ensure_ascii=False, default=str))
            else:
                parts.append(str(item))
        return "\n".join([p for p in parts if p]).strip()

    if isinstance(content, dict):
        text = content.get("text")
        if isinstance(text, str):
            return text
        return json.dumps(content, ensure_ascii=False, default=str)

    return str(content)


def _show_esp_info(info_path: str):
    """æ˜¾ç¤º ESP æå€¼ä¿¡æ¯çš„è¾…åŠ©å‡½æ•°ã€‚"""
    try:
        import json as json_module
        with open(info_path, 'r') as f:
            esp_info = json_module.load(f)
        
        st.markdown("---")
        st.markdown("**ESP æå€¼ä¿¡æ¯**")
        col_max, col_min = st.columns(2)
        with col_max:
            max_val = esp_info.get('ESP_max_eV', 'N/A')
            max_loc = esp_info.get('ESP_max_location_Ang', [])
            st.metric("æœ€å¤§å€¼ (eV)", f"{max_val:.4f}" if isinstance(max_val, (int, float)) else max_val)
            if max_loc:
                st.caption(f"ä½ç½®: ({max_loc[0]:.2f}, {max_loc[1]:.2f}, {max_loc[2]:.2f}) Ã…")
        with col_min:
            min_val = esp_info.get('ESP_min_eV', 'N/A')
            min_loc = esp_info.get('ESP_min_location_Ang', [])
            st.metric("æœ€å°å€¼ (eV)", f"{min_val:.4f}" if isinstance(min_val, (int, float)) else min_val)
            if min_loc:
                st.caption(f"ä½ç½®: ({min_loc[0]:.2f}, {min_loc[1]:.2f}, {min_loc[2]:.2f}) Ã…")
    except Exception:
        pass


def render_message_with_download(role: str, content: Any, key_prefix: str):
    """å°†ç‰¹æ®Šæ ‡è®°æ¸²æŸ“ä¸ºå¯äº¤äº’ç»„ä»¶ã€‚"""
    text = normalize_chat_content(content)

    with st.chat_message(role):
        structure_match = re.search(r"\[\[STRUCTURE_PREVIEW:(.*?)\]\]", text)
        analysis_match = re.search(r"\[\[ANALYSIS_VISUALIZATION:(.*?)\|(.*?)\]\]", text)
        download_match = re.search(r"\[\[DOWNLOAD:(.*?)\]\]", text)
        
        display_text = re.sub(r"\[\[STRUCTURE_PREVIEW:.*?\]\]", "", text)
        display_text = re.sub(r"\[\[ANALYSIS_VISUALIZATION:.*?\]\]", "", display_text)
        display_text = re.sub(r"\[\[DOWNLOAD:.*?\]\]", "", display_text).strip()
        st.write(display_text)

        if analysis_match:
            db_path = analysis_match.group(1).strip()
            infer_dir = analysis_match.group(2).strip()
            
            st.markdown("### ğŸ”¬ åˆ†æç»“æœå¯è§†åŒ–")
            
            # æŸ¥æ‰¾ Li deformation æ–‡ä»¶å’Œ ESP æ–‡ä»¶
            li_deform_files = find_li_deformation_files(infer_dir)
            esp_files_list = find_esp_files(infer_dir)
            has_esp = len(esp_files_list) > 0
            
            # æŸ¥æ‰¾è½¨é“æ–‡ä»¶
            orbital_files = find_orbital_files(infer_dir)
            has_homo = len(orbital_files.get('homo', [])) > 0
            has_lumo = len(orbital_files.get('lumo', [])) > 0
            
            # æ ¹æ®å¯ç”¨æ–‡ä»¶å†³å®š tab æ•°é‡
            tab_names = ["ğŸ§¬ å›¢ç°‡ç»“æ„"]
            if has_homo:
                tab_names.append("ğŸ”µ HOMO è½¨é“")
            if has_lumo:
                tab_names.append("ğŸŸ¢ LUMO è½¨é“")
            if has_esp:
                tab_names.append("âš¡ é™ç”µåŠ¿ (ESP)")
            if li_deform_files:
                tab_names.append("ğŸ’  Li Deformation")
            
            tabs = st.tabs(tab_names)
            tab_idx = 0
            tab_structure = tabs[tab_idx]; tab_idx += 1
            tab_homo = tabs[tab_idx] if has_homo else None; tab_idx += (1 if has_homo else 0)
            tab_lumo = tabs[tab_idx] if has_lumo else None; tab_idx += (1 if has_lumo else 0)
            tab_esp = tabs[tab_idx] if has_esp else None; tab_idx += (1 if has_esp else 0)
            tab_li_deform = tabs[tab_idx] if li_deform_files else None
            
            # é¢„åŠ è½½ç»“æ„ä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆä¸€è‡´çš„æ ‡ç­¾
            structure_labels = {}  # id -> label æ˜ å°„
            structures_data = []   # ä¿å­˜ç»“æ„æ•°æ®ä¾›å¤ç”¨
            if os.path.exists(db_path):
                try:
                    structures_data = load_all_structures_from_db(db_path, max_count=20)
                    for i, (atoms, meta) in enumerate(structures_data):
                        solv_name = meta.get('solvent_name', '')
                        anion_name = meta.get('anion_name', '')
                        n_solv = meta.get('n_solv', 0)
                        n_anion = meta.get('n_anion', 0)
                        category = meta.get('category', '')
                        
                        if anion_name and n_anion > 0:
                            label = f"{n_solv}{solv_name}+{n_anion}{anion_name}"
                        else:
                            label = f"{n_solv}{solv_name}"
                        if category:
                            label = f"[{category}] {label}"
                        structure_labels[str(i)] = label
                except Exception:
                    pass
            
            def get_structure_label(file_id: str, index: int) -> str:
                """æ ¹æ®æ–‡ä»¶ ID è·å–ç»“æ„æ ‡ç­¾ã€‚"""
                if file_id in structure_labels:
                    return structure_labels[file_id]
                # å°è¯•ç”¨ index æŸ¥æ‰¾
                if str(index) in structure_labels:
                    return structure_labels[str(index)]
                return f"ç»“æ„{file_id}"
            
            with tab_structure:
                if os.path.exists(db_path):
                    try:
                        total_count = len(structures_data) if structures_data else get_structure_count_from_db(db_path)
                        max_display = 3  # æœ€å¤šæ˜¾ç¤º 3 ä¸ªç»“æ„
                        
                        if total_count <= 1:
                            # å•ä¸ªç»“æ„
                            if structures_data:
                                atoms, meta = structures_data[0]
                            else:
                                atoms = load_structure_from_db(db_path)
                                meta = {}
                            if atoms:
                                viewer_html = create_gaussian_view_style_viewer(
                                    atoms,
                                    width=650,
                                    height=500,
                                    style="sphere+stick",
                                    add_lighting=True
                                )
                                components.html(viewer_html, height=560, scrolling=False)
                                st.caption(f"åŒ–å­¦å¼: {atoms.get_chemical_formula()} | åŸå­æ•°: {len(atoms)}")
                            else:
                                st.warning("æ— æ³•åŠ è½½ç»“æ„é¢„è§ˆ")
                        else:
                            # å¤šä¸ªç»“æ„
                            displayed_count = min(total_count, max_display)
                            st.markdown(f"**å…± {total_count} ä¸ªå›¢ç°‡ï¼Œæ˜¾ç¤ºå‰ {displayed_count} ä¸ª**")
                            
                            structures_to_show = structures_data[:max_display]
                            
                            if structures_to_show:
                                # ç”Ÿæˆå­ tab åç§°ï¼Œå¤ç”¨ structure_labels
                                sub_tab_names = [f"#{i+1}: {structure_labels.get(str(i), f'ç»“æ„{i}')}" 
                                                 for i in range(len(structures_to_show))]
                                
                                sub_tabs = st.tabs(sub_tab_names)
                                
                                for i, (sub_tab, (atoms, meta)) in enumerate(zip(sub_tabs, structures_to_show)):
                                    with sub_tab:
                                        viewer_html = create_gaussian_view_style_viewer(
                                            atoms,
                                            width=650,
                                            height=450,
                                            style="sphere+stick",
                                            add_lighting=True
                                        )
                                        components.html(viewer_html, height=510, scrolling=False)
                                        
                                        # æ˜¾ç¤ºé…æ–¹ä¿¡æ¯
                                        solv_name = meta.get('solvent_name', 'Unknown')
                                        anion_name = meta.get('anion_name', '')
                                        n_solv = meta.get('n_solv', 0)
                                        n_anion = meta.get('n_anion', 0)
                                        ion = meta.get('ion', 'Li')
                                        
                                        formula_parts = [f"1x{ion}âº"]
                                        if n_solv > 0:
                                            formula_parts.append(f"{n_solv}x{solv_name}")
                                        if n_anion > 0 and anion_name:
                                            formula_parts.append(f"{n_anion}x{anion_name}â»")
                                        
                                        st.caption(f"é…æ–¹: {' + '.join(formula_parts)} | åŒ–å­¦å¼: {atoms.get_chemical_formula()} | åŸå­æ•°: {len(atoms)}")
                                
                                if total_count > max_display:
                                    st.info(f"ğŸ’¡ è¿˜æœ‰ {total_count - max_display} ä¸ªå›¢ç°‡æœªæ˜¾ç¤ºã€‚å®Œæ•´ç»“æœè¯·ä¸‹è½½åˆ†æåŒ…æŸ¥çœ‹ã€‚")
                            else:
                                st.warning("æ— æ³•åŠ è½½ç»“æ„é¢„è§ˆ")
                    except Exception as e:
                        st.error(f"ç»“æ„é¢„è§ˆå¤±è´¥: {e}")
                else:
                    st.warning(f"ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            
            # HOMO Tab
            if tab_homo is not None and has_homo:
                with tab_homo:
                    homo_files = orbital_files.get('homo', [])
                    try:
                        # ç­‰å€¼é¢è®¾ç½®
                        st.markdown("**ç­‰å€¼é¢è®¾ç½®**")
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            homo_iso = st.slider(
                                "ç­‰å€¼é¢å¤§å°",
                                min_value=0.005,
                                max_value=0.1,
                                value=0.02,
                                step=0.005,
                                format="%.3f",
                                key=f"{key_prefix}_homo_iso",
                                help="è°ƒå¤§ï¼šè½¨é“åŒ…ç»œé¢æ”¶ç¼©ï¼›è°ƒå°ï¼šè½¨é“åŒ…ç»œé¢æ‰©å±•"
                            )
                        with col2:
                            st.metric("å½“å‰å€¼", f"{homo_iso:.3f}")
                        
                        if len(homo_files) == 1:
                            # å•ä¸ªæ–‡ä»¶
                            homo_html = create_orbital_viewer(
                                homo_files[0]['path'],
                                width=650,
                                height=500,
                                iso_value=homo_iso,
                                orbital_type="HOMO"
                            )
                            components.html(homo_html, height=560, scrolling=False)
                            st.caption(f"æ–‡ä»¶: {os.path.basename(homo_files[0]['path'])}")
                        else:
                            # å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ tabs åˆ‡æ¢
                            st.markdown(f"**å…± {len(homo_files)} ä¸ª HOMO è½¨é“æ–‡ä»¶**")
                            homo_tab_names = [f"#{i+1}: {get_structure_label(f['id'], i)}" for i, f in enumerate(homo_files)]
                            homo_sub_tabs = st.tabs(homo_tab_names)
                            
                            for i, (sub_tab, homo_file) in enumerate(zip(homo_sub_tabs, homo_files)):
                                with sub_tab:
                                    homo_html = create_orbital_viewer(
                                        homo_file['path'],
                                        width=650,
                                        height=450,
                                        iso_value=homo_iso,
                                        orbital_type="HOMO"
                                    )
                                    components.html(homo_html, height=510, scrolling=False)
                                    st.caption(f"æ–‡ä»¶: {os.path.basename(homo_file['path'])}")
                    except Exception as e:
                        st.error(f"HOMO å¯è§†åŒ–å¤±è´¥: {e}")
            
            # LUMO Tab
            if tab_lumo is not None and has_lumo:
                with tab_lumo:
                    lumo_files = orbital_files.get('lumo', [])
                    try:
                        # ç­‰å€¼é¢è®¾ç½®
                        st.markdown("**ç­‰å€¼é¢è®¾ç½®**")
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            lumo_iso = st.slider(
                                "ç­‰å€¼é¢å¤§å°",
                                min_value=0.005,
                                max_value=0.1,
                                value=0.02,
                                step=0.005,
                                format="%.3f",
                                key=f"{key_prefix}_lumo_iso",
                                help="è°ƒå¤§ï¼šè½¨é“åŒ…ç»œé¢æ”¶ç¼©ï¼›è°ƒå°ï¼šè½¨é“åŒ…ç»œé¢æ‰©å±•"
                            )
                        with col2:
                            st.metric("å½“å‰å€¼", f"{lumo_iso:.3f}")
                        
                        if len(lumo_files) == 1:
                            # å•ä¸ªæ–‡ä»¶
                            lumo_html = create_orbital_viewer(
                                lumo_files[0]['path'],
                                width=650,
                                height=500,
                                iso_value=lumo_iso,
                                orbital_type="LUMO"
                            )
                            components.html(lumo_html, height=560, scrolling=False)
                            st.caption(f"æ–‡ä»¶: {os.path.basename(lumo_files[0]['path'])}")
                        else:
                            # å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ tabs åˆ‡æ¢
                            st.markdown(f"**å…± {len(lumo_files)} ä¸ª LUMO è½¨é“æ–‡ä»¶**")
                            lumo_tab_names = [f"#{i+1}: {get_structure_label(f['id'], i)}" for i, f in enumerate(lumo_files)]
                            lumo_sub_tabs = st.tabs(lumo_tab_names)
                            
                            for i, (sub_tab, lumo_file) in enumerate(zip(lumo_sub_tabs, lumo_files)):
                                with sub_tab:
                                    lumo_html = create_orbital_viewer(
                                        lumo_file['path'],
                                        width=650,
                                        height=450,
                                        iso_value=lumo_iso,
                                        orbital_type="LUMO"
                                    )
                                    components.html(lumo_html, height=510, scrolling=False)
                                    st.caption(f"æ–‡ä»¶: {os.path.basename(lumo_file['path'])}")
                    except Exception as e:
                        st.error(f"LUMO å¯è§†åŒ–å¤±è´¥: {e}")
            
            # ESP (é™ç”µåŠ¿) Tab
            if tab_esp is not None and has_esp:
                with tab_esp:
                    try:
                        st.markdown("**é™ç”µåŠ¿ (ESP) å¯è§†åŒ–**")
                        st.caption("å±•ç¤ºåˆ†å­è¡¨é¢é™ç”µåŠ¿åˆ†å¸ƒï¼šçº¢è‰²ä¸ºæ­£ï¼ˆäº²æ ¸åŒºåŸŸï¼‰ï¼Œè“è‰²ä¸ºè´Ÿï¼ˆäº²ç”µåŒºåŸŸï¼‰")
                        
                        # è‰²é˜¶èŒƒå›´æ§åˆ¶ (eV)
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            esp_range_ev = st.slider(
                                "è‰²é˜¶èŒƒå›´ (eV)",
                                min_value=0.2,
                                max_value=3.0,
                                value=0.82,  # é»˜è®¤ 0.03 a.u. â‰ˆ 0.82 eV
                                step=0.1,
                                format="%.2f",
                                key=f"{key_prefix}_esp_range",
                                help="è°ƒæ•´ ESP è‰²é˜¶çš„æ˜¾ç¤ºèŒƒå›´ï¼Œè¶…å‡ºèŒƒå›´çš„å€¼ä¼šè¢«æˆªæ–­åˆ°è¾¹ç•Œé¢œè‰²"
                            )
                        with col2:
                            st.metric("Â±èŒƒå›´", f"{esp_range_ev:.2f} eV")
                        
                        # è½¬æ¢ä¸ºåŸå­å•ä½ (a.u.)
                        HARTREE_TO_EV = 27.2114
                        esp_colorscale_max = esp_range_ev / HARTREE_TO_EV
                        
                        if len(esp_files_list) == 1:
                            # å•ä¸ª ESP æ–‡ä»¶ç»„
                            esp_files = esp_files_list[0]
                            esp_html = create_esp_viewer(
                                esp_files['density'],
                                esp_files['esp'],
                                esp_files.get('info'),
                                width=650,
                                height=500,
                                esp_colorscale_min=-esp_colorscale_max,
                                esp_colorscale_max=esp_colorscale_max,
                            )
                            components.html(esp_html, height=600, scrolling=False)
                            
                            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                            st.caption(f"å¯†åº¦æ–‡ä»¶: {os.path.basename(esp_files['density'])}")
                            st.caption(f"ESPæ–‡ä»¶: {os.path.basename(esp_files['esp'])}")
                            
                            # å¦‚æœæœ‰ ESP infoï¼Œæ˜¾ç¤ºæå€¼ä¿¡æ¯
                            if esp_files.get('info') and os.path.exists(esp_files['info']):
                                _show_esp_info(esp_files['info'])
                        else:
                            # å¤šä¸ª ESP æ–‡ä»¶ç»„ï¼Œä½¿ç”¨ tabs åˆ‡æ¢
                            st.markdown(f"**å…± {len(esp_files_list)} ä¸ª ESP æ–‡ä»¶**")
                            esp_tab_names = [f"#{i+1}: {get_structure_label(f['id'], i)}" for i, f in enumerate(esp_files_list)]
                            esp_sub_tabs = st.tabs(esp_tab_names)
                            
                            for i, (sub_tab, esp_files) in enumerate(zip(esp_sub_tabs, esp_files_list)):
                                with sub_tab:
                                    esp_html = create_esp_viewer(
                                        esp_files['density'],
                                        esp_files['esp'],
                                        esp_files.get('info'),
                                        width=650,
                                        height=450,
                                        esp_colorscale_min=-esp_colorscale_max,
                                        esp_colorscale_max=esp_colorscale_max,
                                    )
                                    components.html(esp_html, height=510, scrolling=False)
                                    
                                    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                                    st.caption(f"å¯†åº¦æ–‡ä»¶: {os.path.basename(esp_files['density'])}")
                                    
                                    # å¦‚æœæœ‰ ESP infoï¼Œæ˜¾ç¤ºæå€¼ä¿¡æ¯
                                    if esp_files.get('info') and os.path.exists(esp_files['info']):
                                        _show_esp_info(esp_files['info'])
                                
                    except Exception as e:
                        st.error(f"ESP å¯è§†åŒ–å¤±è´¥: {e}")
            
            # Li Deformation Tab
            if tab_li_deform is not None and li_deform_files:
                with tab_li_deform:
                    try:
                        st.markdown("**Li ç¦»å­å˜å½¢å› å­å¯è§†åŒ–**")
                        st.caption("å±•ç¤º Li ç¦»å­å‘¨å›´ç”µå­å¯†åº¦å˜å½¢çš„ç­‰å€¼é¢åˆ†å¸ƒ")
                        
                        # æŸ¥æ‰¾å¯¹åº”çš„åˆ†å­ç»“æ„ xyz æ–‡ä»¶
                        # ä¼˜å…ˆä» task ç›®å½•çš„ xyz_all ä¸­æŸ¥æ‰¾
                        task_dir = os.path.dirname(os.path.dirname(infer_dir))
                        xyz_all_dir = os.path.join(task_dir, "xyz_all")
                        
                        # æ”¶é›†æ‰€æœ‰ xyz æ–‡ä»¶ï¼ŒæŒ‰ç¼–å·æ’åº
                        xyz_files_map = {}
                        if os.path.exists(xyz_all_dir):
                            import glob as glob_module
                            xyz_files = glob_module.glob(os.path.join(xyz_all_dir, "*.xyz"))
                            for xf in xyz_files:
                                basename = os.path.basename(xf)
                                # å°è¯•ä»æ–‡ä»¶åæå–ç¼–å·
                                m = re.search(r'(\d+)', basename)
                                if m:
                                    xyz_files_map[m.group(1)] = xf
                                else:
                                    xyz_files_map['0'] = xf
                        
                        # é€æ˜åº¦æ§åˆ¶
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            opacity = st.slider(
                                "è¡¨é¢é€æ˜åº¦",
                                min_value=0.1,
                                max_value=1.0,
                                value=0.65,
                                step=0.05,
                                format="%.2f",
                                key=f"{key_prefix}_li_deform_opacity",
                                help="è°ƒæ•´ Li deformation è¡¨é¢çš„é€æ˜åº¦"
                            )
                        with col2:
                            st.metric("é€æ˜åº¦", f"{opacity:.2f}")
                        
                        if len(li_deform_files) == 1:
                            # å•ä¸ª Li deformation æ–‡ä»¶
                            li_file = li_deform_files[0]
                            molecule_path = xyz_files_map.get(li_file['id'], list(xyz_files_map.values())[0] if xyz_files_map else None)
                            
                            if molecule_path is None and os.path.exists(db_path):
                                # ä» db å¯¼å‡º
                                from emolagent.visualization import atoms_to_xyz_string
                                atoms = load_structure_from_db(db_path)
                                if atoms:
                                    temp_xyz_path = os.path.join(infer_dir, "temp_molecule.xyz")
                                    with open(temp_xyz_path, 'w') as f:
                                        f.write(atoms_to_xyz_string(atoms, "Generated for Li Deformation visualization"))
                                    molecule_path = temp_xyz_path
                            
                            if molecule_path is None:
                                st.warning("æœªæ‰¾åˆ°åˆ†å­ç»“æ„æ–‡ä»¶ï¼Œæ— æ³•å åŠ æ˜¾ç¤º")
                            else:
                                li_deform_html = create_li_deformation_viewer(
                                    molecule_path=molecule_path,
                                    surface_pdb_path=li_file['path'],
                                    width=650,
                                    height=500,
                                    surface_opacity=opacity,
                                    isovalue=li_file.get('isovalue', '0.09'),
                                )
                                components.html(li_deform_html, height=560, scrolling=False)
                                st.caption(f"æ–‡ä»¶: {os.path.basename(li_file['path'])} | ç­‰å€¼é¢: {li_file.get('isovalue', 'N/A')}")
                        else:
                            # å¤šä¸ª Li deformation æ–‡ä»¶ï¼Œä½¿ç”¨ tabs åˆ‡æ¢
                            st.markdown(f"**å…± {len(li_deform_files)} ä¸ª Li Deformation æ–‡ä»¶**")
                            li_tab_names = [f"#{i+1}: {get_structure_label(f['id'], i)}" for i, f in enumerate(li_deform_files)]
                            li_sub_tabs = st.tabs(li_tab_names)
                            
                            for i, (sub_tab, li_file) in enumerate(zip(li_sub_tabs, li_deform_files)):
                                with sub_tab:
                                    # æ ¹æ® li_file çš„ id æŸ¥æ‰¾å¯¹åº”çš„ xyz æ–‡ä»¶
                                    molecule_path = xyz_files_map.get(li_file['id'])
                                    if molecule_path is None and xyz_files_map:
                                        molecule_path = list(xyz_files_map.values())[0]
                                    
                                    if molecule_path is None and os.path.exists(db_path):
                                        # ä» db å¯¼å‡º
                                        from emolagent.visualization import atoms_to_xyz_string
                                        atoms_list = load_all_structures_from_db(db_path, max_count=len(li_deform_files))
                                        if atoms_list and i < len(atoms_list):
                                            atoms, _ = atoms_list[i]
                                            temp_xyz_path = os.path.join(infer_dir, f"temp_molecule_{i}.xyz")
                                            with open(temp_xyz_path, 'w') as f:
                                                f.write(atoms_to_xyz_string(atoms, f"Structure {i} for Li Deformation"))
                                            molecule_path = temp_xyz_path
                                    
                                    if molecule_path is None:
                                        st.warning("æœªæ‰¾åˆ°åˆ†å­ç»“æ„æ–‡ä»¶ï¼Œæ— æ³•å åŠ æ˜¾ç¤º")
                                    else:
                                        li_deform_html = create_li_deformation_viewer(
                                            molecule_path=molecule_path,
                                            surface_pdb_path=li_file['path'],
                                            width=650,
                                            height=450,
                                            surface_opacity=opacity,
                                            isovalue=li_file.get('isovalue', '0.09'),
                                        )
                                        components.html(li_deform_html, height=510, scrolling=False)
                                        st.caption(f"æ–‡ä»¶: {os.path.basename(li_file['path'])} | ç­‰å€¼é¢: {li_file.get('isovalue', 'N/A')}")
                    except Exception as e:
                        st.error(f"Li Deformation å¯è§†åŒ–å¤±è´¥: {e}")

        elif structure_match:
            db_path = structure_match.group(1).strip()
            if os.path.exists(db_path):
                # è·å–æ•°æ®åº“ä¸­çš„ç»“æ„æ€»æ•°
                total_count = get_structure_count_from_db(db_path)
                max_display = 3  # æœ€å¤šæ˜¾ç¤º 3 ä¸ªç»“æ„
                
                if total_count <= 1:
                    # å•ä¸ªç»“æ„ï¼šä¿æŒåŸæœ‰é€»è¾‘
                    st.markdown("### ğŸ“Š ç»“æ„é¢„è§ˆ")
                    
                    with st.expander("ğŸ”¬ ç‚¹å‡»æŸ¥çœ‹ 3D åˆ†å­ç»“æ„ (å¯äº¤äº’)", expanded=True):
                        try:
                            atoms = load_structure_from_db(db_path)
                            if atoms:
                                viewer_html = create_gaussian_view_style_viewer(
                                    atoms,
                                    width=650,
                                    height=500,
                                    style="sphere+stick",
                                    add_lighting=True
                                )
                                components.html(viewer_html, height=550, scrolling=False)
                                
                                st.caption(f"ğŸ“ ç»“æ„è·¯å¾„: `{db_path}`")
                                st.info("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥è¯´ã€Œå¯¹ä¸Šé¢ç”Ÿæˆçš„ç»“æ„è¿›è¡Œç”µå­ç»“æ„åˆ†æã€æ¥ç»§ç»­åˆ†æ")
                            else:
                                st.warning("æ— æ³•åŠ è½½ç»“æ„é¢„è§ˆ")
                        except Exception as e:
                            st.error(f"ç»“æ„é¢„è§ˆå¤±è´¥: {e}")
                else:
                    # å¤šä¸ªç»“æ„ï¼šä½¿ç”¨ tabs å±•ç¤º
                    displayed_count = min(total_count, max_display)
                    st.markdown(f"### ğŸ“Š ç»“æ„é¢„è§ˆ (å…± {total_count} ä¸ªå›¢ç°‡ï¼Œæ˜¾ç¤ºå‰ {displayed_count} ä¸ª)")
                    
                    try:
                        structures = load_all_structures_from_db(db_path, max_count=max_display)
                        
                        if structures:
                            # ç”Ÿæˆ tab åç§°
                            tab_names = []
                            for i, (atoms, meta) in enumerate(structures):
                                solv_name = meta.get('solvent_name', '')
                                anion_name = meta.get('anion_name', '')
                                n_solv = meta.get('n_solv', 0)
                                n_anion = meta.get('n_anion', 0)
                                category = meta.get('category', '')
                                
                                # æ„å»ºç®€æ´çš„æ ‡ç­¾
                                if anion_name and n_anion > 0:
                                    label = f"{n_solv}{solv_name}+{n_anion}{anion_name}"
                                else:
                                    label = f"{n_solv}{solv_name}"
                                if category:
                                    label = f"[{category}] {label}"
                                tab_names.append(f"ç»“æ„{i+1}: {label}")
                            
                            tabs = st.tabs(tab_names)
                            
                            for i, (tab, (atoms, meta)) in enumerate(zip(tabs, structures)):
                                with tab:
                                    viewer_html = create_gaussian_view_style_viewer(
                                        atoms,
                                        width=650,
                                        height=500,
                                        style="sphere+stick",
                                        add_lighting=True
                                    )
                                    components.html(viewer_html, height=550, scrolling=False)
                                    
                                    # æ˜¾ç¤ºé…æ–¹ä¿¡æ¯
                                    solv_name = meta.get('solvent_name', 'Unknown')
                                    anion_name = meta.get('anion_name', '')
                                    n_solv = meta.get('n_solv', 0)
                                    n_anion = meta.get('n_anion', 0)
                                    ion = meta.get('ion', 'Li')
                                    
                                    formula_parts = [f"1x{ion}âº"]
                                    if n_solv > 0:
                                        formula_parts.append(f"{n_solv}x{solv_name}")
                                    if n_anion > 0 and anion_name:
                                        formula_parts.append(f"{n_anion}x{anion_name}â»")
                                    
                                    st.caption(f"é…æ–¹: {' + '.join(formula_parts)} | åŒ–å­¦å¼: {atoms.get_chemical_formula()} | åŸå­æ•°: {len(atoms)}")
                            
                            # å¦‚æœæœ‰æ›´å¤šæœªæ˜¾ç¤ºçš„ç»“æ„
                            if total_count > max_display:
                                st.info(f"ğŸ’¡ è¿˜æœ‰ {total_count - max_display} ä¸ªå›¢ç°‡æœªæ˜¾ç¤ºã€‚å®Œæ•´ç»“æœè¯·ä¸‹è½½åˆ†æåŒ…æŸ¥çœ‹ã€‚")
                            
                            st.caption(f"ğŸ“ ç»“æ„è·¯å¾„: `{db_path}`")
                            st.info("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥è¯´ã€Œå¯¹ä¸Šé¢ç”Ÿæˆçš„ç»“æ„è¿›è¡Œç”µå­ç»“æ„åˆ†æã€æ¥ç»§ç»­åˆ†æ")
                        else:
                            st.warning("æ— æ³•åŠ è½½ç»“æ„é¢„è§ˆ")
                    except Exception as e:
                        st.error(f"ç»“æ„é¢„è§ˆå¤±è´¥: {e}")

        if download_match:
            file_path = download_match.group(1).strip()
            if os.path.exists(file_path):
                with open(file_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“¦ ä¸‹è½½åˆ†æç»“æœå‹ç¼©åŒ… (.zip)",
                        data=f,
                        file_name=os.path.basename(file_path),
                        mime="application/zip",
                        key=f"{key_prefix}_download",
                    )


def main():
    """ä¸»å‡½æ•°ã€‚"""

    schedule_cleanup()
    cookie_manager = get_manager()

    if "user" not in st.session_state:
        st.session_state["user"] = None

    if st.session_state["user"] is None and not st.session_state.get("logout_flag", False):
        token = cookie_manager.get("auth_token")
        if token:
            user_info = db.verify_jwt_token(token)
            if user_info:
                st.session_state["user"] = user_info
                st.session_state["current_chat_id"] = None

    if st.session_state["user"] is None:
        login_ui(cookie_manager)
        return

    current_user = st.session_state["user"]
    if "suppress_autocreate" not in st.session_state:
        st.session_state["suppress_autocreate"] = False

    # 1. Sidebar
    with st.sidebar:
        st.write(f"ğŸ‘¤ **{current_user['username']}**")
        if st.button("ç™»å‡º", type="secondary"):
            st.session_state["user"] = None
            st.session_state["messages"] = []
            st.session_state["current_chat_id"] = None
            st.session_state["logout_flag"] = True
            cookie_manager.delete("auth_token")
            st.rerun()

        st.markdown("---")
        if st.button("+ æ–°å»ºå¯¹è¯", type="primary", use_container_width=True):
            st.session_state["suppress_autocreate"] = False
            new_id = db.create_conversation(current_user["id"], title="New Chat")
            st.session_state["current_chat_id"] = new_id
            st.session_state["messages"] = [{"role": "assistant", "content": WELCOME_MESSAGE}]
            db.add_message(new_id, "assistant", WELCOME_MESSAGE)
            st.rerun()

        st.markdown("### ğŸ•’ å†å²è®°å½•")
        conversations = db.get_user_conversations(current_user["id"])
        for chat in conversations:
            btn_type = "primary" if st.session_state.get("current_chat_id") == chat["id"] else "secondary"
            col1, col2 = st.columns([0.8, 0.2])
            with col1:
                if st.button(
                    f"ğŸ“„ {chat['title']}",
                    key=f"chat_{chat['id']}",
                    type=btn_type,
                    use_container_width=True,
                ):
                    st.session_state["current_chat_id"] = chat["id"]
                    msgs = db.get_conversation_messages(chat["id"])
                    st.session_state["messages"] = msgs if msgs else []
                    st.rerun()
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"del_{chat['id']}"):
                    if len(conversations) == 1:
                        st.session_state["suppress_autocreate"] = True
                        st.session_state["current_chat_id"] = None
                        st.session_state["messages"] = []
                    safe_username = "".join([c for c in current_user["username"] if c.isalnum() or c in ("-", "_")])
                    chat_folder = os.path.join(get_project_root(), "users", safe_username, "output", str(chat["id"]))
                    if os.path.exists(chat_folder):
                        try:
                            shutil.rmtree(chat_folder)
                        except Exception as e:
                            st.toast(f"âš ï¸ æ–‡ä»¶å¤¹åˆ é™¤å¤±è´¥: {e}")
                    db.delete_conversation(chat["id"])
                    if st.session_state.get("current_chat_id") == chat["id"]:
                        st.session_state["current_chat_id"] = None
                        st.session_state["messages"] = []
                    st.rerun()

        st.markdown("---")
        st.header("æ¨¡å‹è®¾ç½®")
        model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-pro"],
            index=0,
        )
        api_key = os.getenv("GOOGLE_API_KEY", "")
        temperature = st.slider("Temperature", 0.0, 1.0, 0.0)

        st.markdown("---")
        st.header("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
        
        try:
            kb_stats = get_index_stats(api_key)
            if "error" not in kb_stats:
                st.metric("å·²ç´¢å¼•æ–‡æ¡£å—", kb_stats.get("total_documents", 0))
                st.caption(f"å·²ç´¢å¼•æ–‡ä»¶æ•°: {kb_stats.get('indexed_files', 0)}")
            else:
                st.warning("çŸ¥è¯†åº“æœªåˆå§‹åŒ–")
        except Exception:
            st.warning("çŸ¥è¯†åº“æœªåˆå§‹åŒ–")
        
        if current_user.get("username") in ADMIN_USERS:
            col_idx1, col_idx2 = st.columns(2)
            with col_idx1:
                if st.button("ğŸ”„ å¢é‡æ›´æ–°", use_container_width=True):
                    with st.spinner("æ­£åœ¨æ›´æ–°çŸ¥è¯†åº“ç´¢å¼•..."):
                        try:
                            stats = build_index(api_key, force_rebuild=False)
                            st.success(
                                f"ç´¢å¼•å®Œæˆï¼\n"
                                f"æ–°å¢: {stats['new_indexed']}, "
                                f"è·³è¿‡: {stats['skipped']}, "
                                f"å¤±è´¥: {stats['failed']}"
                            )
                        except Exception as e:
                            st.error(f"ç´¢å¼•å¤±è´¥: {e}")
            
            with col_idx2:
                if st.button("ğŸ”¨ é‡å»ºç´¢å¼•", use_container_width=True):
                    with st.spinner("æ­£åœ¨é‡å»ºçŸ¥è¯†åº“ç´¢å¼•ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."):
                        try:
                            stats = build_index(api_key, force_rebuild=True)
                            st.success(
                                f"é‡å»ºå®Œæˆï¼\n"
                                f"å…±ç´¢å¼• {stats['new_indexed']} ä¸ªæ–‡ä»¶, "
                                f"{stats['total_chunks']} ä¸ªæ–‡æ¡£å—"
                            )
                        except Exception as e:
                            st.error(f"ç´¢å¼•å¤±è´¥: {e}")

        st.markdown("---")
        st.header("ğŸ–¥ï¸ GPU ä»»åŠ¡çŠ¶æ€")
        try:
            queue_status = get_task_queue_status()
            col_q1, col_q2 = st.columns(2)
            with col_q1:
                st.metric("è¿è¡Œä¸­", f"{queue_status['active_tasks']}")
            with col_q2:
                st.metric("æœ€å¤§å¹¶å‘", f"{queue_status['max_tasks']}")
            
            # æ˜¾ç¤ºæ¯å¼  GPU çš„è´Ÿè½½
            gpu_loads = queue_status.get('gpu_loads', {})
            if gpu_loads:
                st.caption("**GPU è´Ÿè½½åˆ†å¸ƒ:**")
                gpu_cols = st.columns(len(gpu_loads))
                for i, (gpu_id, load) in enumerate(sorted(gpu_loads.items())):
                    with gpu_cols[i]:
                        max_per_gpu = queue_status['max_tasks'] // len(gpu_loads)
                        st.metric(f"GPU {gpu_id}", f"{load}/{max_per_gpu}")
            
            if queue_status['can_accept']:
                st.success(f"âœ… å¯æ¥å—æ–°ä»»åŠ¡ (å‰©ä½™ {queue_status['available_slots']} æ§½ä½)")
            else:
                st.warning(f"â³ é˜Ÿåˆ—å·²æ»¡ï¼Œæ–°ä»»åŠ¡éœ€æ’é˜Ÿç­‰å¾…")
        except Exception as e:
            st.caption(f"æ— æ³•è·å–é˜Ÿåˆ—çŠ¶æ€: {e}")

    # 2. Session Init
    if st.session_state.get("current_chat_id") is None:
        user_conversations = db.get_user_conversations(current_user["id"])
        if user_conversations:
            latest_chat = user_conversations[0]
            st.session_state["current_chat_id"] = latest_chat["id"]
            msgs = db.get_conversation_messages(latest_chat["id"])
            st.session_state["messages"] = msgs if msgs else []
        else:
            if st.session_state.get("suppress_autocreate"):
                st.session_state["current_chat_id"] = None
                st.session_state["messages"] = []
            else:
                new_id = db.create_conversation(current_user["id"], title="New Chat")
                st.session_state["current_chat_id"] = new_id
                st.session_state["messages"] = [{"role": "assistant", "content": WELCOME_MESSAGE}]
                db.add_message(new_id, "assistant", WELCOME_MESSAGE)

    if st.session_state.get("current_chat_id") is None:
        st.title("ğŸ§ª EMolAgent")
        st.info("æš‚æ— å¯¹è¯ï¼Œè¯·åœ¨å·¦ä¾§ç‚¹å‡» [+ æ–°å»ºå¯¹è¯] æŒ‰é’®ã€‚")
        return

    # 3. LLM Setup
    if not api_key:
        st.warning("âš ï¸ Google API Key æ— æ•ˆã€‚")
        st.stop()

    try:
        agent = build_agent(model_name=model_name, temperature=temperature, api_key=api_key)
    except Exception as e:
        st.error(f"æ¨¡å‹/Agent åˆå§‹åŒ–å¤±è´¥: {e}")
        st.stop()

    # 4. Chat Interface
    st.title("ğŸ§ª EMolAgent")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    for idx, msg in enumerate(st.session_state["messages"]):
        render_message_with_download(
            role=msg["role"],
            content=msg["content"],
            key_prefix=f"history_{idx}",
        )

    # 5. Handle Input
    if prompt_input := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
        st.session_state.messages.append({"role": "user", "content": prompt_input})
        st.chat_message("user").write(prompt_input)

        current_chat_id = st.session_state["current_chat_id"]
        db.add_message(current_chat_id, "user", prompt_input)

        if len(st.session_state.messages) <= 2:
            db.update_conversation_title(current_chat_id, prompt_input[:20])

        config = {"configurable": {"thread_id": str(current_chat_id)}}
        context = Context(
            user_id=str(current_user.get("id")) if current_user else None,
            username=current_user.get("username") if current_user else None,
            chat_id=str(current_chat_id),
        )

        with st.spinner("æ­£åœ¨æ€è€ƒå’Œæ‰§è¡Œä»»åŠ¡..."):
            try:
                response: dict[str, Any] = agent.invoke(
                    {"messages": [{"role": "user", "content": prompt_input}]},
                    config=config,
                    context=context,
                )

                output_text = None
                msgs = response.get("messages") if isinstance(response, dict) else None
                if msgs and isinstance(msgs, list):
                    last = msgs[-1]
                    if isinstance(last, dict):
                        output_text = last.get("content")
                    else:
                        output_text = getattr(last, "content", None)

                if not output_text and isinstance(response, dict):
                    output_text = response.get("output") or response.get("structured_response")

                if not output_text:
                    output_text = str(response)

                output_text_str = normalize_chat_content(output_text)

                render_message_with_download(
                    role="assistant",
                    content=output_text_str,
                    key_prefix="current_run",
                )

                st.session_state.messages.append({"role": "assistant", "content": output_text_str})
                db.add_message(current_chat_id, "assistant", output_text_str)

            except Exception as e:
                error_msg = f"æ‰§è¡Œå‡ºé”™: {str(e)}"
                render_message_with_download(
                    role="assistant",
                    content=error_msg,
                    key_prefix="current_run_error",
                )
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
                db.add_message(current_chat_id, "assistant", error_msg)


if __name__ == "__main__":
    main()
